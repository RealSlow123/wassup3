{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6002dcc9-7527-4970-96b5-7cbfce2ca693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyinstaller\n",
      "  Downloading pyinstaller-6.8.0-py3-none-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: setuptools>=42.0.0 in c:\\users\\gkdme\\anaconda3\\lib\\site-packages (from pyinstaller) (68.2.2)\n",
      "Collecting altgraph (from pyinstaller)\n",
      "  Downloading altgraph-0.17.4-py2.py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pyinstaller-hooks-contrib>=2024.6 (from pyinstaller)\n",
      "  Downloading pyinstaller_hooks_contrib-2024.7-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\gkdme\\anaconda3\\lib\\site-packages (from pyinstaller) (23.1)\n",
      "Collecting pefile>=2022.5.30 (from pyinstaller)\n",
      "  Downloading pefile-2023.2.7-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pywin32-ctypes>=0.2.1 (from pyinstaller)\n",
      "  Downloading pywin32_ctypes-0.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Downloading pyinstaller-6.8.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.3/1.3 MB 41.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 27.4 MB/s eta 0:00:00\n",
      "Downloading pefile-2023.2.7-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.8/71.8 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading pyinstaller_hooks_contrib-2024.7-py2.py3-none-any.whl (341 kB)\n",
      "   ---------------------------------------- 0.0/341.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 341.3/341.3 kB ? eta 0:00:00\n",
      "Downloading pywin32_ctypes-0.2.2-py3-none-any.whl (30 kB)\n",
      "Downloading altgraph-0.17.4-py2.py3-none-any.whl (21 kB)\n",
      "Installing collected packages: altgraph, pywin32-ctypes, pyinstaller-hooks-contrib, pefile, pyinstaller\n",
      "  Attempting uninstall: pywin32-ctypes\n",
      "    Found existing installation: pywin32-ctypes 0.2.0\n",
      "    Uninstalling pywin32-ctypes-0.2.0:\n",
      "      Successfully uninstalled pywin32-ctypes-0.2.0\n",
      "Successfully installed altgraph-0.17.4 pefile-2023.2.7 pyinstaller-6.8.0 pyinstaller-hooks-contrib-2024.7 pywin32-ctypes-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206958e5-0d78-4798-ab4f-8cf8c25edf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import math, time, os, pandas as pd, urllib.request\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--window-size=974,1047')\n",
    "options.add_argument('--window-position=-7,0')\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "search = input('검색어:')\n",
    "cnt = int(input('스크래핑 할 건수는 몇건입니까?: '))\n",
    "page_cnt = math.ceil(cnt / 10)  # 크롤링 할 전체 페이지 수 \n",
    "\n",
    "now = time.localtime()\n",
    "date_format = '%04d%02d%02d'%(now.tm_year, now.tm_mon, now.tm_mday)\n",
    "f_dir = f'{os.getcwd()}\\\\{search}여행기사_{cnt}건_{date_format}'\n",
    "os.makedirs(f_dir)\n",
    "\n",
    "URL = 'https://korean.visitkorea.or.kr/search/search_list.do?keyword='+search\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(URL)\n",
    "time.sleep(2)\n",
    "# 여행기사 더보기 클릭\n",
    "driver.find_element(By.CSS_SELECTOR, \"#s_recommend > .more_view > a\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "title_list = []\n",
    "contents_list = []\n",
    "img_url_list = []\n",
    "\n",
    "def page_work():\n",
    "    result = driver.find_elements(By.CSS_SELECTOR,'#search_result .tit>a')\n",
    "    global contents_no, cnt\n",
    "    global title_list, contents_list, img_url_list\n",
    "\n",
    "    for item in result:\n",
    "        contents_no += 1\n",
    "\n",
    "        if contents_no <= cnt :    \n",
    "            print(f'[콘텐츠 {contents_no}]')  \n",
    "            item.send_keys(Keys.ENTER) # .click()은 에러 잘남\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            # 이미지 추출을 위해 미리 스크롤\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "            html = driver.page_source\n",
    "            html_dom = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            title = html_dom.find(id='topTitle')\n",
    "            title_list.append(title.text)\n",
    "            print(title.text)\n",
    "\n",
    "            img_tag_list = html_dom.select('.img_typeBox img')\n",
    "            img_url_list = [item['src'] for item in img_tag_list]\n",
    "\n",
    "            contents = driver.find_elements(By.CLASS_NAME, 'txt_p')\n",
    "            contents_merge = ' '.join([item.text for item in contents])        \n",
    "            contents_list.append(contents_merge)           \n",
    "\n",
    "            driver.back()\n",
    "            time.sleep(2)     \n",
    "\n",
    "\n",
    "def file_export():\n",
    "\n",
    "    DF = pd.DataFrame({\"제목\":title_list, \"내용\":contents_list})\n",
    "    filename = f'{search}여행기사_{cnt}건_{date_format}.xlsx'\n",
    "    DF.to_excel(f_dir+'\\\\'+filename)\n",
    "    print(f'====== {page_no} 페이지 {filename} 파일 저장 완료 ======')\n",
    "\n",
    "\n",
    "    no = 0\n",
    "    for src in img_url_list:\n",
    "        # 다운로드  (주소, 파일이름)\n",
    "        urllib.request.urlretrieve(src, f'{f_dir}\\\\{page_no}_{no}.jpg')\n",
    "        no += 1\n",
    "    print(f'====== {page_no} 페이지 {f_dir} 디렉토리 이미지 저장 완료 ======')\n",
    "\n",
    "\n",
    "contents_no = 0\n",
    "today = time.localtime()\n",
    "print('스크래핑 프로그램 실행')\n",
    "\n",
    "for page_no in range(1, page_cnt+1):    \n",
    "    print(f'====== {page_no} 페이지 스크래핑 시작 ======')\n",
    "    page_work()\n",
    "    print(f'====== {page_no} 페이지 스크래핑 작업중 ======')\n",
    "    file_export()\n",
    "    print(f'====== {page_no} 페이지 스크래핑 완료 ======')\n",
    "    if page_no < page_cnt:\n",
    "        driver.find_element(By.XPATH, f'/html/body/div[3]/div/div[1]/div[14]/a[{page_no+1}]').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "print('스크래핑 프로그램 종료')\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0e4ddc2-c797-4054-8be7-f26d6eeb603c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "검색어: 제주도\n",
      "스크래핑 할 건수는 몇건입니까?:  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크래핑 프로그램 실행\n",
      "====== 1 페이지 스크래핑 시작 ======\n",
      "[콘텐츠 1]\n",
      "해변산책부터 레이싱까지, 제주 반려동물 동반여행 추천 코스\n",
      "[콘텐츠 2]\n"
     ]
    },
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: stale element not found\n  (Session info: chrome=123.0.6312.58); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF68BD97032+63090]\n\t(No symbol) [0x00007FF68BD02C82]\n\t(No symbol) [0x00007FF68BB9EC65]\n\t(No symbol) [0x00007FF68BBAE78B]\n\t(No symbol) [0x00007FF68BBAEFEA]\n\t(No symbol) [0x00007FF68BBA4B29]\n\t(No symbol) [0x00007FF68BBA2D3A]\n\t(No symbol) [0x00007FF68BBA6159]\n\t(No symbol) [0x00007FF68BBA6200]\n\t(No symbol) [0x00007FF68BBE5664]\n\t(No symbol) [0x00007FF68BBE5752]\n\t(No symbol) [0x00007FF68BBDD152]\n\t(No symbol) [0x00007FF68BC06FDA]\n\t(No symbol) [0x00007FF68BBDA00A]\n\t(No symbol) [0x00007FF68BC071F0]\n\t(No symbol) [0x00007FF68BC23412]\n\t(No symbol) [0x00007FF68BC06D83]\n\t(No symbol) [0x00007FF68BBD83A8]\n\t(No symbol) [0x00007FF68BBD9441]\n\tGetHandleVerifier [0x00007FF68C1925AD+4238317]\n\tGetHandleVerifier [0x00007FF68C1CF70D+4488525]\n\tGetHandleVerifier [0x00007FF68C1C79EF+4456495]\n\tGetHandleVerifier [0x00007FF68BE70576+953270]\n\t(No symbol) [0x00007FF68BD0E54F]\n\t(No symbol) [0x00007FF68BD09224]\n\t(No symbol) [0x00007FF68BD0935B]\n\t(No symbol) [0x00007FF68BCF9B94]\n\tBaseThreadInitThunk [0x00007FFC996E257D+29]\n\tRtlUserThreadStart [0x00007FFC9B12AF28+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 92\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_no \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, page_cnt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):    \n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m====== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 페이지 스크래핑 시작 ======\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 92\u001b[0m     page_work()\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m====== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 페이지 스크래핑 작업중 ======\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m     file_export()\n",
      "Cell \u001b[1;32mIn[22], line 45\u001b[0m, in \u001b[0;36mpage_work\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[콘텐츠 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontents_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#import pdb;pdb.set_trace()\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m             item\u001b[38;5;241m.\u001b[39msend_keys(Keys\u001b[38;5;241m.\u001b[39mENTER) \u001b[38;5;66;03m# .click()은 에러 잘남\u001b[39;00m\n\u001b[0;32m     47\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     49\u001b[0m             \u001b[38;5;66;03m# 이미지 추출을 위해 미리 스크롤\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:231\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    228\u001b[0m             remote_files\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload(file))\n\u001b[0;32m    229\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remote_files)\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(\n\u001b[0;32m    232\u001b[0m     Command\u001b[38;5;241m.\u001b[39mSEND_KEYS_TO_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(keys_to_typing(value)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: keys_to_typing(value)}\n\u001b[0;32m    233\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: stale element not found\n  (Session info: chrome=123.0.6312.58); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF68BD97032+63090]\n\t(No symbol) [0x00007FF68BD02C82]\n\t(No symbol) [0x00007FF68BB9EC65]\n\t(No symbol) [0x00007FF68BBAE78B]\n\t(No symbol) [0x00007FF68BBAEFEA]\n\t(No symbol) [0x00007FF68BBA4B29]\n\t(No symbol) [0x00007FF68BBA2D3A]\n\t(No symbol) [0x00007FF68BBA6159]\n\t(No symbol) [0x00007FF68BBA6200]\n\t(No symbol) [0x00007FF68BBE5664]\n\t(No symbol) [0x00007FF68BBE5752]\n\t(No symbol) [0x00007FF68BBDD152]\n\t(No symbol) [0x00007FF68BC06FDA]\n\t(No symbol) [0x00007FF68BBDA00A]\n\t(No symbol) [0x00007FF68BC071F0]\n\t(No symbol) [0x00007FF68BC23412]\n\t(No symbol) [0x00007FF68BC06D83]\n\t(No symbol) [0x00007FF68BBD83A8]\n\t(No symbol) [0x00007FF68BBD9441]\n\tGetHandleVerifier [0x00007FF68C1925AD+4238317]\n\tGetHandleVerifier [0x00007FF68C1CF70D+4488525]\n\tGetHandleVerifier [0x00007FF68C1C79EF+4456495]\n\tGetHandleVerifier [0x00007FF68BE70576+953270]\n\t(No symbol) [0x00007FF68BD0E54F]\n\t(No symbol) [0x00007FF68BD09224]\n\t(No symbol) [0x00007FF68BD0935B]\n\t(No symbol) [0x00007FF68BCF9B94]\n\tBaseThreadInitThunk [0x00007FFC996E257D+29]\n\tRtlUserThreadStart [0x00007FFC9B12AF28+40]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import math, time, os, pandas as pd, urllib.request\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--window-size=974,1047')\n",
    "options.add_argument('--window-position=-7,0')\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "search = input('검색어:')\n",
    "cnt = int(input('스크래핑 할 건수는 몇건입니까?: '))\n",
    "page_cnt = math.ceil(cnt / 10)  # 크롤링 할 전체 페이지 수 \n",
    "\n",
    "now = time.localtime()\n",
    "date_format = '%04d%02d%02d'%(now.tm_year, now.tm_mon, now.tm_mday)\n",
    "f_dir = f'{os.getcwd()}\\\\{search}여행기사_{cnt}건_{date_format}'\n",
    "os.makedirs(f_dir)\n",
    "\n",
    "URL = 'https://korean.visitkorea.or.kr/search/search_list.do?keyword='+search\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(URL)\n",
    "time.sleep(2)\n",
    "# 여행기사 더보기 클릭\n",
    "driver.find_element(By.CSS_SELECTOR, \"#s_recommend > .more_view > a\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "title_list = []\n",
    "contents_list = []\n",
    "img_url_list = []\n",
    "\n",
    "def page_work():\n",
    "    result = driver.find_elements(By.CSS_SELECTOR,'#search_result .tit>a')\n",
    "    global contents_no, cnt\n",
    "    global title_list, contents_list, img_url_list\n",
    "\n",
    "    for item in result:\n",
    "        contents_no += 1\n",
    "\n",
    "        if contents_no <= cnt :    \n",
    "            print(f'[콘텐츠 {contents_no}]')\n",
    "#import pdb;pdb.set_trace()\n",
    "            item.send_keys(Keys.ENTER) # .click()은 에러 잘남\n",
    "            \n",
    "            time.sleep(2)\n",
    "\n",
    "            # 이미지 추출을 위해 미리 스크롤\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "            html = driver.page_source\n",
    "            html_dom = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            title = html_dom.find(id='topTitle')\n",
    "            title_list.append(title.text)\n",
    "            print(title.text)\n",
    "\n",
    "            img_tag_list = html_dom.select('.img_typeBox img')\n",
    "            img_url_list = [item['src'] for item in img_tag_list]\n",
    "\n",
    "            contents = driver.find_elements(By.CLASS_NAME, 'txt_p')\n",
    "            contents_merge = ' '.join([item.text for item in contents])        \n",
    "            contents_list.append(contents_merge)           \n",
    "\n",
    "            driver.back()\n",
    "            time.sleep(2)     \n",
    "\n",
    "\n",
    "def file_export():\n",
    "\n",
    "    DF = pd.DataFrame({\"제목\":title_list, \"내용\":contents_list})\n",
    "    filename = f'{search}여행기사_{cnt}건_{date_format}.xlsx'\n",
    "    DF.to_excel(f_dir+'\\\\'+filename)\n",
    "    print(f'====== {page_no} 페이지 {filename} 파일 저장 완료 ======')\n",
    "\n",
    "\n",
    "    no = 0\n",
    "    for src in img_url_list:\n",
    "        # 다운로드  (주소, 파일이름)\n",
    "        urllib.request.urlretrieve(src, f'{f_dir}\\\\{page_no}_{no}.jpg')\n",
    "        no += 1\n",
    "    print(f'====== {page_no} 페이지 {f_dir} 디렉토리 이미지 저장 완료 ======')\n",
    "\n",
    "\n",
    "contents_no = 0\n",
    "today = time.localtime()\n",
    "print('스크래핑 프로그램 실행')\n",
    "\n",
    "for page_no in range(1, page_cnt+1):    \n",
    "    print(f'====== {page_no} 페이지 스크래핑 시작 ======')\n",
    "    page_work()\n",
    "    print(f'====== {page_no} 페이지 스크래핑 작업중 ======')\n",
    "    file_export()\n",
    "    print(f'====== {page_no} 페이지 스크래핑 완료 ======')\n",
    "    if page_no < page_cnt:\n",
    "        driver.find_element(By.XPATH, f'/html/body/div[3]/div/div[1]/div[14]/a[{page_no+1}]').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "print('스크래핑 프로그램 종료')\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
